{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-05T21:49:54.740569Z",
     "start_time": "2024-01-05T21:49:54.724713Z"
    }
   },
   "outputs": [],
   "source": [
    "import environments_fully_observable \n",
    "import environments_partially_observable\n",
    "import numpy as np\n",
    "from  tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x300 with 5 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# function to standardize getting an env for the whole notebook\n",
    "def get_env(n=1000):\n",
    "    # n is the number of boards that you want to simulate parallely\n",
    "    # size is the size of each board, also considering the borders\n",
    "    # mask for the partially observable, is the size of the local neighborhood\n",
    "    size = 7\n",
    "    e = environments_fully_observable.OriginalSnakeEnvironment(n, size)\n",
    "    # or environments_partially_observable.OriginalSnakeEnvironment(n, size, 2)\n",
    "    return e\n",
    "env_ = get_env()\n",
    "GAMMA = .9\n",
    "ITERATIONS = 5000\n",
    "\n",
    "fig,axs=plt.subplots(1,min(len(env_.boards), 5), figsize=(10,3))\n",
    "for ax, board in zip(axs, env_.boards):\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.imshow(board, origin=\"lower\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T21:51:24.586654Z",
     "start_time": "2024-01-05T21:51:24.492663Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define the models that you need ()\n",
    "agent = ...\n",
    "value = ...\n",
    "q = ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for iteration in trange(ITERATIONS):\n",
    "    # get current state of the boards\n",
    "    state = env_.to_state()\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \"\"\" \n",
    "        tensor of actions, consider that\n",
    "            UP = 0\n",
    "            RIGHT = 1\n",
    "            DOWN = 2\n",
    "            LEFT = 3\n",
    "        \"\"\"\n",
    "        actions = ... \n",
    "        rewards = env_.move(actions)\n",
    "        new_state = tf.constant(env_.to_state())\n",
    "\n",
    "        # calculate the loss of whichever algorithm you have picked\n",
    "        loss = ...\n",
    "\n",
    "    gradient = tape.gradient(..., ...)\n",
    "    optimizer.apply_gradients(zip(gradient, ...))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### Random policy reward\n",
    " \n",
    "Just a baseline (not the one you are supposed to develop)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_env = get_env(100)\n",
    "random_rewards = []\n",
    "\n",
    "for _ in trange(1000):\n",
    "    probs = tf.convert_to_tensor([[.25]*4]*random_env.n_boards)\n",
    "    #sample actions\n",
    "    actions =  tf.random.categorical(tf.math.log(probs), 1, dtype=tf.int32)\n",
    "    # MDP update\n",
    "    rewards = random_env.move(actions)\n",
    "    random_rewards.append(np.mean(rewards))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
